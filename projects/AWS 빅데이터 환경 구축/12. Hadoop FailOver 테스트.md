---
style: |
  img {
    display: block;
    float: none;
    margin-left: auto;
    margin-right: auto;
  }
marp: true
paginate: true
---
# [Hadoop FailOver 테스트](https://www.youtube.com/watch?v=QQUKRVmdGVc&list=PLJlUnZ1kDbt7X2C4ntIYHmphNDIc5wN8J&index=13)
- [관련 문서](https://biggongjam.notion.site/12-Hadoop-FailOver-4093eb227a004ce98e1813ed6cdd6614)
- 테스트 시나리오
  - nn1에서 Active 상태인 namenode 프로세스를 kill 하고, nn2의 namenode가 active로 활성화 되는지 확인한다.

---
### 단계1: NameNode 상태 확인 
```shell
# EC2 Ubuntu terminal(nn1)
ssh nn1

hdfs haadmin -getServiceState namenode1 
hdfs haadmin -getServiceState namenode2
```
![Alt text](./img/12.%20Hadoop%20FailOver%20테스트/image-2.png)

---
### 단계2: nn1 서버의 NameNode kill
```shell
# EC2 Ubuntu terminal(nn1)

# jps 프로세스 확인
jps

1664 NameNode
2786 JobHistoryServer
4359 Jps

# NameNode 프로세스 kill
kill -9 1664

# NameNode2 상태 확인
hdfs haadmin -getServiceState namenode2
```
![bg right w:600](./img/12.%20Hadoop%20FailOver%20테스트/image-3.png)

---
### 단계3: Hadoop WEB UI 확인
- nn1 서버는 접속 불가 
- nn2 서버는 active 상태 
![Alt text](./img/12.%20Hadoop%20FailOver%20테스트/image-4.png)







