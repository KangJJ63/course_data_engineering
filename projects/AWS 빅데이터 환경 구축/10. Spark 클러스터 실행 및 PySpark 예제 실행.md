---
style: |
  img {
    display: block;
    float: none;
    margin-left: auto;
    margin-right: auto;
  }
marp: true
paginate: true
---
# [Hadoop & Yarn 클러스터 실행](https://www.youtube.com/watch?v=QQUKRVmdGVc&list=PLJlUnZ1kDbt7X2C4ntIYHmphNDIc5wN8J&index=11)
- [관련 문서](https://biggongjam.notion.site/10-Spark-PySpark-56678b8608d9419783d202ddfed1f3ef)

---
### 단계1: nn1 서버 > (Spark) start-all.sh 실행
```shell
# EC2 Ubuntu terminal(nn1)

$SPARK_HOME/sbin/start-all.sh
```
![w:800](./img/10.%20Spark%20클러스터%20실행%20및%20PySpark%20예제%20실행/image-2.png)
- jps로 결과 확인 

![w:800](./img/10.%20Spark%20클러스터%20실행%20및%20PySpark%20예제%20실행/image-3.png)

---
### 단계2: nn1 서버 > Spark Word Count 예제 테스트
- cluster 모드로 실행 > 출력값 확인 x 
```shell
# EC2 Ubuntu terminal(nn1)

spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster --driver-memory 512m --executor-memory 512m --executor-cores 1 $SPARK_HOME/examples/jars/spark-examples_2.12-3.2.1.jar 5
```
![Alt text](./img/10.%20Spark%20클러스터%20실행%20및%20PySpark%20예제%20실행/image-4.png)

---
- client 모드로 실행 > 출력값 확인 o  
```shell
# EC2 Ubuntu terminal(nn1)

spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client --driver-memory 512m --executor-memory 512m --executor-cores 1 $SPARK_HOME/examples/jars/spark-examples_2.12-3.2.1.jar 5
```
![Alt text](./img/10.%20Spark%20클러스터%20실행%20및%20PySpark%20예제%20실행/image-5.png)

---
### 단계3: nn1 서버 > PySpark 예제1
```shell
# EC2 Ubuntu terminal(nn1)

# 스크립트 편집
vim pyspark_example.py

# pyspark_example.py 아래 내용 저장
from pyspark import SparkContext, SparkConf

conf = SparkConf()
conf.setMaster("yarn")
conf.setAppName("PySpark Test")
sc = SparkContext(conf=conf)

print("="*100, "\n")
print(sc)
print("="*100, "\n")
```
---
```shell
# 실행 명령어
clear && spark-submit --master yarn --deploy-mode client pyspark_example.py
or
clear && spark-submit --master yarn --deploy-mode cluster pyspark_example.py
```
![w:900](./img/10.%20Spark%20클러스터%20실행%20및%20PySpark%20예제%20실행/image-6.png)

---
### 단계4: nn1 서버 > PySpark 예제2
```shell
cd ./Downloads # csv 파일이 있는 위치로 이동 
```
![Alt text](./img/10.%20Spark%20클러스터%20실행%20및%20PySpark%20예제%20실행/image-7.png)

---
```shell
# Mac local terminal

# nn1 서버로 csv 파일 업로드
scp KC_KOBIS_BOX_OFFIC_MOVIE_INFO_202105.csv nn1:~/
```
![Alt text](./img/10.%20Spark%20클러스터%20실행%20및%20PySpark%20예제%20실행/image-8.png)

---
```shell
# EC2 Ubuntu terminal(nn1)

# HDFS로 csv 파일 업로드
hdfs dfs -put KC_KOBIS_BOX_OFFIC_MOVIE_INFO_202105.csv /test/

# HDFS 디렉토리 확인
hdfs dfs -ls /test
```
![Alt text](./img/10.%20Spark%20클러스터%20실행%20및%20PySpark%20예제%20실행/image-9.png)

---
- pyspark_example2.py 편집 
```shell
# 스크립트 편집
vim pyspark_example2.py

# pyspark_example2.py 아래 내용 저장
from pyspark.sql import SparkSession

sc = SparkSession.builder\
        .master("yarn")\
        .appName("PySpark Test")\
        .getOrCreate()

df = sc.read.csv("hdfs:///test/KC_KOBIS_BOX_OFFIC_MOVIE_INFO_202105.csv", header=True)

df.show()
```
---
- 실행 
```shell
# 실행 명령어
clear && spark-submit --master yarn --deploy-mode client pyspark_example2.py
``` 
![w:700](./img/10.%20Spark%20클러스터%20실행%20및%20PySpark%20예제%20실행/image-10.png)




