---
style: |
  img {
    display: block;
    float: none;
    margin-left: auto;
    margin-right: auto;
  }
marp: true
paginate: true
---
# 라이브러리 설치 및 설정 
생성된 인스턴스(EC2)에 접속하여 라이브러리 설치 및 설정을 진행 

---
### 단계1: 다운로드 및 설치 
- 필수 라이브러리 설치 및 업데이트
```shell
# 업데이트 목록 갱신
sudo apt-get -y update
# 현재 패키지 업그레이드 
sudo apt-get -y upgrade
# 신규 업데이트 설치 
sudo apt-get -y dist-upgrade
# 필요 라이브러리 설치 
sudo apt-get install -y vim wget unzip ssh openssh-* net-tools
```

---
- Java 8 설치 
```shell
# Java 8 설치 
sudo apt-get install -y openjdk-8-jdk
# Java version 확인 
java -version
# Java 경로 확인 
ls -al /etc/alternatives/java # /usr/lib/jvm/java-8-openjdk-amd64
```

---
- Apache Hadoop 3.2.2 설치 
```shell
# 설치파일 관리용 디렉토리 생성
sudo mkdir /install_dir && cd /install_dir
# Hadoop 3.3.0 설치
sudo wget https://archive.apache.org/dist/hadoop/core/hadoop-3.3.0/hadoop-3.3.0.tar.gz
# Hadoop 3.3.0 압축 해제
sudo tar -zxvf hadoop-3.3.0.tar.gz -C /usr/local
# Hadoop 3.3.0 압축 해제 확인 
ls -al /usr/local/hadoop-3.3.0/

# owner(소유권)를 root로 변경 
sudo chown root:root -R /usr/local/hadoop-3.3.0/
# owner(소유권)이 root로 변경되었는지 확인 
ls -al /usr/local/hadoop-3.3.0/
```

---
- Python & PySpark 설치 
```shell
# Python 설치
sudo apt-get install -y python3-pip
# Python 버전 확인
python3 --version

# PySpark 설치
sudo pip3 install pyspark findspark
```

---
- scala 설치 
```shell
# scala 설치 
sudo wget https://downloads.lightbend.com/scala/2.13.5/scala-2.13.5.tgz
# scala-2.13.5 압축 해제
sudo tar -zxvf scala-2.13.5.tgz -C /usr/local
# owner(소유권)를 root로 변경 
sudo chown root:root -R /usr/local/scala-2.13.5/
# owner(소유권)이 root로 변경되었는지 확인 
ls -al /usr/local/scala-2.13.5/

# scala 실행 
/usr/local/scala-2.13.5/bin/scala
```
![w:700](./img/3.%20인스턴스에%20라이브러리%20설치%20및%20설정/image-3.png)

---
- Apache Spark 설치
```shell
# Spark 3.1.2 설치
sudo wget https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz
# Spark 3.1.2 압축 해제
sudo tar -xzvf spark-3.1.2-bin-hadoop3.2.tgz -C /usr/local
# owner(소유권)를 root로 변경 
sudo chown root:root -R /usr/local/spark-3.1.2-bin-hadoop3.2/
# owner(소유권)이 root로 변경되었는지 확인 
ls -al /usr/local/spark-3.1.2-bin-hadoop3.2/

# spark 실행 
/usr/local/spark-3.1.2-bin-hadoop3.2/bin/spark-shell
```
![w:700](./img/3.%20인스턴스에%20라이브러리%20설치%20및%20설정/image-4.png)

---
### 단계2: 환경 설정 
- profile
```shell
# profile 수정 
sudo vim /etc/profile

# profile에 아래 내용 추가 
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/usr/local/hadoop-3.3.0
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export SPARK_HOME=/usr/local/spark-3.1.2-bin-hadoop3.2

# profile 추가한 내용 확인 
tail /etc/profile

# 추가된 내용 활성화 
source /etc/profile
```

---
![Alt text](./img/3.%20인스턴스에%20라이브러리%20설치%20및%20설정/image-5.png)

---
- .bashrc
```shell
# .bashrc 수정 
sudo vim ~/.bashrc

# .bashrc에 아래 내용 추가 
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/usr/local/hadoop-3.3.0
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export SPARK_HOME=/usr/local/spark-3.1.2-bin-hadoop3.2

# 추가된 내용 활성화 
source ~/.bashrc
# 활성화된 내용 확인 
env | grep SPARK
```
![w:700](./img/3.%20인스턴스에%20라이브러리%20설치%20및%20설정/image-6.png)

---
### 단계3: Hadoop 설정 
- hadoop 설정 디렉토리로 이동 
```shell
cd $HADOOP_HOME/etc/hadoop
```
![Alt text](./img/3.%20인스턴스에%20라이브러리%20설치%20및%20설정/image-7.png)

---
- core-site.xml
  - 하둡 시스템 설정 파일로, 로그파일, 네트워크 튜닝, I/O튜닝, 파일시스템튜닝, 압축 등 시스템 설정 파일.
  - HDFS 와 맵리듀스에서 공통적으로 사용할 환경정보를 입력 

- 주요속성
  - `fs.defaultFS` : HDFS 기본 파일시스템 디렉토리를 지정한다.

```shell
sudo vim core-site.xml
# 아래 작성한 xml 내용을 추가함
```
```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
    </property>
</configuration>
```

---
- hdfs-site.xml
  - HDFS에서 사용할 환경 정보를 설정하는 파일이다.

- 주요속성
  - `dfs.replication` : HDFS 파일 블록 복제 개수 지정한다.
  - `dfs.namenode.name.dir` : NameNode에서 관리할 데이터 디렉토리 경로 지정한다.
  - `dfs.datanode.data.dir` : DataNode에서 관리할 데이터 디렉토리 경로 지정한다.

---
```shell
sudo vim hdfs-site.xml
# 아래 작성한 xml 내용을 추가함
```
```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///hdfs_dir/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///hdfs_dir/datanode</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>worker01:50090</value>
    </property>
</configuration>
```

---
- yarn-site.xml
  - Resource Manager 및 Node Manager에 대한 구성을 정의한다.

```shell
sudo vim yarn-site.xml
# 아래 작성한 xml 내용을 추가함
```
```xml
<configuration>
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>file:///hdfs_dir/yarn/local</value>
    </property>
    <property>
        <name>yarn.nodemanager.log-dirs</name>
        <value>file:///hdfs_dir/yarn/logs</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>master</value>
    </property>
</configuration>
```

---
- mapred-site.xml
  - MapReduce 어플리케이션 설정 파일을 편집한다.

```shell
sudo vim mapred-site.xml
# 아래 작성한 xml 내용을 추가함
```
```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

---
### 단계4: Hadoop 환경변수 설정 
- hadoop-env.sh
  - hadoop 환경 설정 파일에 Java 설정 및 Hadoop 사용자 설정.

```shell
sudo vim hadoop-env.sh

# 아래 내용 추가 
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HDFS_NAMENODE_USER="root"
export HDFS_DATANODE_USER="root"
export HDFS_SECONDARYNAMENODE_USER="root"
export YARN_RESOURCEMANAGER_USER="root"
export YARN_NODEMANAGER_USER="root"
```

---
### 단계5: spark 설정 
- spark 설정 디렉토리로 이동 
```shell
cd /usr/local/spark-3.1.2-bin-hadoop3.2/conf
```
![Alt text](./img/3.%20인스턴스에%20라이브러리%20설치%20및%20설정/image-8.png)

---
- spark-defaults.conf
```shell
# Spark spark-defaults.conf.template 파일 복사
sudo cp spark-defaults.conf.template spark-defaults.conf

# Spark spark-defaults.conf 파일 설정
sudo vim spark-defaults.conf

# 아래 설정 후 저장 
# 클러스터 매니저 정보
spark.master              yarn
# 스파크 이벤트 로그 수행 유무
# true시 spark.eventLog.dir에 로깅 경로 지정해야합니다 - 스파크 UI에서 확인 가능합니다.
spark.eventLog.enabled    true
# 스파크 이벤트 로그 저장 경로
spark.eventLog.dir        hdfs://namenode:8021/spark_enginelog
```

---
- spark-env.sh
```shell
# spark-env.sh 파일 카피
sudo cp spark-env.sh.template spark-env.sh

# spark-env.sh 파일 편집
sudo vim spark-env.sh

# 아래 내용 수정 후 저장
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export SPARK_MASTER_HOST=master
export HADOOP_HOME=/usr/local/hadoop-3.3.0
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
```
