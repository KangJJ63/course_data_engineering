---
style: |
  img {
    display: block;
    float: none;
    margin-left: auto;
    margin-right: auto;
  }
marp: true
paginate: true
---
# [Hadoop & Yarn 클러스터 실행](https://www.youtube.com/watch?v=QQUKRVmdGVc&list=PLJlUnZ1kDbt7X2C4ntIYHmphNDIc5wN8J&index=10)
- [관련 문서](https://biggongjam.notion.site/9-Hadoop-Yarn-42edb962678b44e9a28976578de0d786)

---
### 단계1: nn1 서버 > Namenode
- Namenode 초기화 
```shell
# EC2 Ubuntu terminal(nn1)

# hdfs namenode 포맷
hdfs namenode -format
```
- Namenode 실행 
```shell
# EC2 Ubuntu terminal(nn1)

# hdfs namenode 실행
hdfs --daemon start namenode

# node 확인 
jps
``` 
![bg right w:600](./img/9.%20Hadoop%20&%20Yarn%20클러스터%20실행/image-2.png)

---
### 단계2: nn2 서버 > Standby NameNode
- Standby NameNode 실행
```shell
# EC2 Ubuntu terminal(nn2)

# hdfs standby namenode 실행
ssh nn2
hdfs namenode -bootstrapStandby
```
---
### 단계3: nn1 서버 > (Hadoop)start-dfs.sh 실행
- 해당 단계에서 “DFSZKFailoverController” 프로세스가 실행 된다.
- nn1 서버에서 장애가 생기면, nn2 서버가 작동하게 된다.
```shell
# EC2 Ubuntu terminal(nn1)

start-dfs.sh
```
![bg right w:600](./img/9.%20Hadoop%20&%20Yarn%20클러스터%20실행/image-3.png)

---
### 단계4: nn1 서버 > (Yarn)start-yarn.sh 실행
- 해당 단계에서 “ResourceManager” 프로세스가 실행된다. 
- 나머지 DataNode 서버에서는 “NodeManager” 프로세스가 실행된다.
```shell

# EC2 Ubuntu terminal(nn1)

start-yarn.sh
```
![bg right w:600](./img/9.%20Hadoop%20&%20Yarn%20클러스터%20실행/image-4.png)

---
- nn1: ResourceManager
- nn2: 없음 
- dn1: DataNode
- dn2: DataNode
- dn3: DataNode

![Alt text](./img/9.%20Hadoop%20&%20Yarn%20클러스터%20실행/image-5.png)

---
### 단계5: nn1 서버 > JobHistory 실행 
- 해당 단계에서 “JobHistoryServer” 프로세스가 실행된다.
```shell
# EC2 Ubuntu terminal(nn1)

mapred --daemon start historyserver
```
![Alt text](./img/9.%20Hadoop%20&%20Yarn%20클러스터%20실행/image-6.png)

---
### 단계6: nn1, nn2 서버 > Active, Standby NameNode 확인
```shell
# EC2 Ubuntu terminal(nn1)

hdfs haadmin -getServiceState namenode1 
hdfs haadmin -getServiceState namenode2
```
![Alt text](./img/9.%20Hadoop%20&%20Yarn%20클러스터%20실행/image-7.png)

---
### 단계7: nn1 서버 > Hadoop Word Count 예제 테스트
```shell
# EC2 Ubuntu terminal(nn1)

# HDFS test 디렉토리 생성
hdfs dfs -mkdir /test
# HDFS LICENSE.txt 파일을 test 디렉토리에 삽입
hdfs dfs -put /usr/local/hadoop/LICENSE.txt /test/
# Word Count 예제 실행
yarn jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar wordcount hdfs:///test/LICENSE.txt /test/output
```
![w:800](./img/9.%20Hadoop%20&%20Yarn%20클러스터%20실행/image-8.png)

---
```shell
# Word Count 결과 확인
hdfs dfs -text /test/output/*
```
![Alt text](./img/9.%20Hadoop%20&%20Yarn%20클러스터%20실행/image-9.png)



